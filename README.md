# LLM Practicals

A hands-on introduction to Large Language Models for [**IndabaX Sudan 2025**](https://indabaxsd.github.io/).

## Overview

This repository contains practical exercises exploring the foundations of LLMs, including tokenization, embeddings, transformer architecture, and attention mechanisms.

## Contents

- `intro_to_LLMs.ipynb` â€” interactive Jupyter notebook with hands-on experiments

- `llm_helpers.py` â€” helper functions for plotting, model utilities, and visualization

## Getting Started

[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1g0wLPcRasMe6INBK8Kg_5co0geoLeCst?usp=sharing)

1. **Make a copy of the notebook in your own Google Drive before running it** (File â†’ Save a copy in Drive).
2. Follow the notebook sequentially and run each cell interactively.
3. Review explanations and complete the small embedded tasks.

## Topics Covered

- ðŸ¤— Hugging Face model loading and interaction

- Tokenization across different languages

- Word embeddings and semantic relationships

- Attention mechanisms and self-attention

- Positional encodings in transformers

## Author

**Asim Mohamed**
ðŸ“§ <amohamed@aimsammi.org>

## License

Open-source educational content for **IndabaX Sudan 2025**.
